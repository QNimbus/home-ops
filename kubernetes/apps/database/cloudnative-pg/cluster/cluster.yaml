---
# yaml-language-server: $schema=https://schemas.clustrs.dev/postgresql.cnpg.io/cluster_v1.json
apiVersion: postgresql.cnpg.io/v1
kind: Cluster
metadata:
  name: &clusterName postgres-v17
spec:
  instances: 3
  imageName: ghcr.io/cloudnative-pg/postgresql:17.5-standard-bookworm
  imagePullPolicy: Always
  primaryUpdateStrategy: unsupervised
  replicationSlots:
    highAvailability:
      enabled: true
    updateInterval: 30
  storage:
    size: 20Gi

  enableSuperuserAccess: true
  superuserSecret:
    name: cloudnative-pg-secret

  postgresql:
    parameters:
      max_connections: "300"
      shared_buffers: 512MB
      pg_stat_statements.max: "10000"
      pg_stat_statements.track: all
    synchronous:
      method: any
      number: 1

  monitoring:
    enablePodMonitor: true

  # Ref: https://github.com/cloudnative-pg/cloudnative-pg/issues/2570
  enablePDB: false

  # Ref: https://www.beyondwatts.com/posts/debugging-barman-xamzcontentsha256mismatch-error-after-upgrading-to-postgresql175/
  env:
    - name: AWS_REQUEST_CHECKSUM_CALCULATION
      value: when_required
    - name: AWS_RESPONSE_CHECKSUM_VALIDATION
      value: when_required

  resources:
    requests:
      cpu: 80m
      memory: 768Mi
    limits:
      memory: 2Gi
  plugins:
    - name: barman-cloud.cloudnative-pg.io
      isWALArchiver: true
      parameters:
        barmanObjectName: &barmanObjectName cloudnative-pg-storj
        serverName: *clusterName

  ## --- DISASTER RECOVERY & INITIAL BOOTSTRAP CONFIGURATION ---
  ## This section controls how the cluster is created. There are two mutually exclusive options:
  ##
  ## 1. `initdb`: Creates a brand new, empty database. Use this ONLY for the very first deployment.
  ## 2. `recovery`: Restores the cluster from an existing S3 backup. Use this for disaster recovery.
  ##
  ## --- PROCEDURE FOR DISASTER RECOVERY (e.g., after a full node reset) ---
  ##
  ## STEP 1: Pause the Flux controller to prevent it from applying a partially edited config.
  ##   `flux suspend kustomization <your-kustomization-name> -n database`
  ##
  ## STEP 2: Edit this file for recovery.
  ##   a. Uncomment the `bootstrap.recovery` section.
  ##   b. Uncomment the `externalClusters` section.
  ##   c. Ensure `externalClusters.serverName` points to the correct S3 backup directory (*clusterName).
  ##
  ## STEP 3: Commit the changes to Git and resume the Flux controller to start the recovery.
  ##   `flux resume kustomization <your-kustomization-name> -n database`
  ##
  ## STEP 4: AFTER the cluster is healthy and restored, revert the changes.
  ##   a. Re-comment the `bootstrap.recovery` and `externalClusters` sections.
  ##   b. Commit the changes. This is CRITICAL to return the cluster to a normal, healthy operational state.
  ## ---

  # bootstrap:
    # --- Option 1: Create a brand new, empty cluster (use on first-ever deploy) ---
    # initdb:
    #   database: postgres
    #   owner: postgres
    #   secret:
    #     name: cloudnative-pg-bootstrap-secret

    # --- Option 2: Recover from an existing S3 backup (use for disaster recovery) ---
    # recovery:
    #   source: &previousCluster postgres-v17-backup # Internal reference, matches 'externalClusters.name'

  # externalClusters:
  #   - name: *previousCluster # Internal reference, matches 'bootstrap.recovery.source'
  #     plugin:
  #       name: barman-cloud.cloudnative-pg.io
  #       parameters:
  #         barmanObjectName: *barmanObjectName
  #         # This MUST point to the S3 directory containing the backups.
  #         serverName: *clusterName
